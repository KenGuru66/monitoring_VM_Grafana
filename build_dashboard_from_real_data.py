#!/usr/bin/env python3
"""
Ğ¡ĞºÑ€Ğ¸Ğ¿Ñ‚ Ğ´Ğ»Ñ Ğ¿Ğ¾ÑÑ‚Ñ€Ğ¾ĞµĞ½Ğ¸Ñ Ğ´Ğ°ÑˆĞ±Ğ¾Ñ€Ğ´Ğ° Grafana Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ….

Ğ¨Ğ°Ğ³Ğ¸:
1. Ğ—Ğ°Ğ¿ÑƒÑĞºĞ°ĞµÑ‚ Ğ¿Ğ°Ñ€ÑĞµÑ€ ÑĞ¾ Ğ’Ğ¡Ğ•ĞœĞ˜ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ°Ğ¼Ğ¸ Ğ¸ Ñ€ĞµÑÑƒÑ€ÑĞ°Ğ¼Ğ¸
2. ĞĞ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµÑ‚ CSV Ğ¸ Ğ¸Ğ·Ğ²Ğ»ĞµĞºĞ°ĞµÑ‚ ÑƒĞ½Ğ¸ĞºĞ°Ğ»ÑŒĞ½Ñ‹Ğµ ĞºĞ¾Ğ¼Ğ±Ğ¸Ğ½Ğ°Ñ†Ğ¸Ğ¸ Resource-Metric
3. Ğ¡Ğ¾Ğ·Ğ´Ğ°ĞµÑ‚ Ğ¼Ğ°Ğ¿Ğ¿Ğ¸Ğ½Ğ³ RESOURCE_TO_METRICS Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…
4. Ğ“ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒĞµÑ‚ Ğ´Ğ°ÑˆĞ±Ğ¾Ñ€Ğ´ Grafana
"""

import subprocess
import sys
import os
import csv
import json
from collections import defaultdict
from pathlib import Path

# Ğ˜Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ğ¸Ñ€ÑƒĞµĞ¼ ÑĞ»Ğ¾Ğ²Ğ°Ñ€Ğ¸
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'Data2csv'))
from METRIC_DICT import METRIC_NAME_DICT
from RESOURCE_DICT import RESOURCE_NAME_DICT

def step1_parse_with_all_metrics(input_zip: str, output_dir: str = "Data2csv/output"):
    """Ğ¨Ğ°Ğ³ 1: ĞŸĞ°Ñ€ÑĞ¸Ğ½Ğ³ ÑĞ¾ Ğ’Ğ¡Ğ•ĞœĞ˜ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ°Ğ¼Ğ¸ Ğ¸ Ñ€ĞµÑÑƒÑ€ÑĞ°Ğ¼Ğ¸"""
    print("="*80)
    print("ğŸ“Š Ğ¨ĞĞ“ 1: ĞŸĞ°Ñ€ÑĞ¸Ğ½Ğ³ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… ÑĞ¾ Ğ’Ğ¡Ğ•ĞœĞ˜ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ°Ğ¼Ğ¸ Ğ¸ Ñ€ĞµÑÑƒÑ€ÑĞ°Ğ¼Ğ¸")
    print("="*80)
    
    # ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµĞ¼ Ğ²ÑĞµ ID Ğ¼ĞµÑ‚Ñ€Ğ¸Ğº Ğ¸ Ñ€ĞµÑÑƒÑ€ÑĞ¾Ğ²
    all_metrics = list(METRIC_NAME_DICT.keys())
    all_resources = list(RESOURCE_NAME_DICT.keys())
    
    print(f"   Ğ’ÑĞµĞ³Ğ¾ Ğ¼ĞµÑ‚Ñ€Ğ¸Ğº: {len(all_metrics)}")
    print(f"   Ğ’ÑĞµĞ³Ğ¾ Ñ€ĞµÑÑƒÑ€ÑĞ¾Ğ²: {len(all_resources)}")
    print()
    
    # ĞÑ‡Ğ¸Ñ‰Ğ°ĞµĞ¼ output Ğ´Ğ¸Ñ€ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ñ
    output_path = Path(output_dir)
    if output_path.exists():
        for csv_file in output_path.glob("*.csv"):
            csv_file.unlink()
            print(f"   âœ… Ğ£Ğ´Ğ°Ğ»ĞµĞ½ ÑÑ‚Ğ°Ñ€Ñ‹Ğ¹ CSV: {csv_file.name}")
    else:
        output_path.mkdir(parents=True)
    
    print()
    print("   â†’ Ğ—Ğ°Ğ¿ÑƒÑĞº Ğ¿Ğ°Ñ€ÑĞµÑ€Ğ°...")
    
    # Ğ¤Ğ¾Ñ€Ğ¼Ğ¸Ñ€ÑƒĞµĞ¼ ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´Ñƒ
    cmd = [
        "python3",
        "Data2csv/Huawei_perf_parser_v0.2_parallel.py",
        "-i", input_zip,
        "-o", output_dir
    ]
    
    # Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ ĞºĞ°Ğ¶Ğ´Ñ‹Ğ¹ Ñ€ĞµÑÑƒÑ€Ñ Ğ¾Ñ‚Ğ´ĞµĞ»ÑŒĞ½Ğ¾
    for resource_id in all_resources:
        cmd.extend(["-r", resource_id])
    
    # Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ ĞºĞ°Ğ¶Ğ´ÑƒÑ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºÑƒ Ğ¾Ñ‚Ğ´ĞµĞ»ÑŒĞ½Ğ¾
    for metric_id in all_metrics:
        cmd.extend(["-m", metric_id])
    
    # Ğ—Ğ°Ğ¿ÑƒÑĞºĞ°ĞµĞ¼ Ğ¿Ğ°Ñ€ÑĞµÑ€
    result = subprocess.run(cmd, capture_output=True, text=True)
    
    if result.returncode != 0:
        print(f"   âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ğ°Ñ€ÑĞ¸Ğ½Ğ³Ğ°:")
        print(result.stderr)
        sys.exit(1)
    
    print("   âœ… ĞŸĞ°Ñ€ÑĞ¸Ğ½Ğ³ Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½!")
    print()
    
    # ĞĞ°Ñ…Ğ¾Ğ´Ğ¸Ğ¼ ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ½Ñ‹Ğ¹ CSV Ñ„Ğ°Ğ¹Ğ»
    csv_files = list(output_path.glob("*.csv"))
    if not csv_files:
        print("   âŒ CSV Ñ„Ğ°Ğ¹Ğ»Ñ‹ Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ñ‹!")
        sys.exit(1)
    
    csv_file = csv_files[0]
    print(f"   ğŸ“ CSV Ñ„Ğ°Ğ¹Ğ»: {csv_file}")
    print(f"   ğŸ“Š Ğ Ğ°Ğ·Ğ¼ĞµÑ€: {csv_file.stat().st_size / (1024**2):.2f} MB")
    print()
    
    return str(csv_file)

def step2_extract_unique_combinations(csv_file: str):
    """Ğ¨Ğ°Ğ³ 2: Ğ˜Ğ·Ğ²Ğ»ĞµÑ‡ĞµĞ½Ğ¸Ğµ ÑƒĞ½Ğ¸ĞºĞ°Ğ»ÑŒĞ½Ñ‹Ñ… ĞºĞ¾Ğ¼Ğ±Ğ¸Ğ½Ğ°Ñ†Ğ¸Ğ¹ Resource-Metric"""
    print("="*80)
    print("ğŸ“‹ Ğ¨ĞĞ“ 2: Ğ˜Ğ·Ğ²Ğ»ĞµÑ‡ĞµĞ½Ğ¸Ğµ ÑƒĞ½Ğ¸ĞºĞ°Ğ»ÑŒĞ½Ñ‹Ñ… ĞºĞ¾Ğ¼Ğ±Ğ¸Ğ½Ğ°Ñ†Ğ¸Ğ¹ Resource-Metric")
    print("="*80)
    
    # Ğ¡Ğ»Ğ¾Ğ²Ğ°Ñ€ÑŒ: Resource ID â†’ set(Metric Names)
    resource_metrics = defaultdict(set)
    
    # Ğ¡Ñ‡ĞµÑ‚Ñ‡Ğ¸ĞºĞ¸
    total_rows = 0
    processed_rows = 0
    
    print("   â†’ Ğ§Ñ‚ĞµĞ½Ğ¸Ğµ CSV Ñ„Ğ°Ğ¹Ğ»Ğ°...")
    
    with open(csv_file, 'r', encoding='utf-8') as f:
        # ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ÑĞµĞ¼ Ñ€Ğ°Ğ·Ğ´ĞµĞ»Ğ¸Ñ‚ĞµĞ»ÑŒ
        first_line = f.readline()
        f.seek(0)
        
        if '\t' in first_line:
            delimiter = '\t'
        elif ';' in first_line:
            delimiter = ';'
        else:
            delimiter = ','
        
        reader = csv.reader(f, delimiter=delimiter)
        
        for row in reader:
            total_rows += 1
            
            if len(row) < 3:
                continue
            
            resource_id = row[0].strip()
            metric_name = row[1].strip()
            
            if resource_id and metric_name:
                resource_metrics[resource_id].add(metric_name)
                processed_rows += 1
            
            # ĞŸÑ€Ğ¾Ğ³Ñ€ĞµÑÑ ĞºĞ°Ğ¶Ğ´Ñ‹Ğµ 100k ÑÑ‚Ñ€Ğ¾Ğº
            if total_rows % 100000 == 0:
                print(f"   ... Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ½Ğ¾ {total_rows:,} ÑÑ‚Ñ€Ğ¾Ğº")
    
    print()
    print(f"   âœ… ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ½Ğ¾ ÑÑ‚Ñ€Ğ¾Ğº: {total_rows:,}")
    print(f"   âœ… Ğ£Ğ½Ğ¸ĞºĞ°Ğ»ÑŒĞ½Ñ‹Ñ… ĞºĞ¾Ğ¼Ğ±Ğ¸Ğ½Ğ°Ñ†Ğ¸Ğ¹: {processed_rows:,}")
    print(f"   âœ… ĞĞ°Ğ¹Ğ´ĞµĞ½Ğ¾ Ñ€ĞµÑÑƒÑ€ÑĞ¾Ğ²: {len(resource_metrics)}")
    print()
    
    # Ğ’Ñ‹Ğ²Ğ¾Ğ´Ğ¸Ğ¼ ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºÑƒ Ğ¿Ğ¾ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ¼Ñƒ Ñ€ĞµÑÑƒÑ€ÑÑƒ
    print("   ğŸ“Š Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ° Ğ¿Ğ¾ Ñ€ĞµÑÑƒÑ€ÑĞ°Ğ¼:")
    print()
    
    for resource_id in sorted(resource_metrics.keys()):
        resource_name = RESOURCE_NAME_DICT.get(resource_id, f"Unknown ({resource_id})")
        metric_count = len(resource_metrics[resource_id])
        print(f"      â€¢ {resource_name:30s} (ID: {resource_id:5s}) - {metric_count:3d} Ğ¼ĞµÑ‚Ñ€Ğ¸Ğº")
    
    print()
    
    return resource_metrics

def step3_create_metric_mapping(resource_metrics: dict):
    """Ğ¨Ğ°Ğ³ 3: Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Ğ¼Ğ°Ğ¿Ğ¿Ğ¸Ğ½Ğ³Ğ° Ğ¼ĞµÑ‚Ñ€Ğ¸Ğº"""
    print("="*80)
    print("ğŸ—ºï¸  Ğ¨ĞĞ“ 3: Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Ğ¼Ğ°Ğ¿Ğ¿Ğ¸Ğ½Ğ³Ğ° Resource â†’ Metrics")
    print("="*80)
    
    # ĞĞ±Ñ€Ğ°Ñ‚Ğ½Ñ‹Ğ¹ Ğ¼Ğ°Ğ¿Ğ¿Ğ¸Ğ½Ğ³: Metric Name â†’ Metric ID
    metric_name_to_id = {}
    for metric_id, metric_name in METRIC_NAME_DICT.items():
        metric_name_to_id[metric_name] = metric_id
    
    # Ğ¡Ğ¾Ğ·Ğ´Ğ°ĞµĞ¼ Ğ¼Ğ°Ğ¿Ğ¿Ğ¸Ğ½Ğ³: Resource ID â†’ [Metric IDs]
    resource_to_metric_ids = {}
    
    for resource_id, metric_names in resource_metrics.items():
        metric_ids = []
        
        for metric_name in sorted(metric_names):
            # ĞĞ°Ñ…Ğ¾Ğ´Ğ¸Ğ¼ ID Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ¸
            metric_id = metric_name_to_id.get(metric_name)
            if metric_id:
                metric_ids.append(metric_id)
            else:
                print(f"   âš ï¸  ĞœĞµÑ‚Ñ€Ğ¸ĞºĞ° '{metric_name}' Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ° Ğ² METRIC_NAME_DICT")
        
        if metric_ids:
            resource_to_metric_ids[resource_id] = metric_ids
    
    print(f"   âœ… Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½ Ğ¼Ğ°Ğ¿Ğ¿Ğ¸Ğ½Ğ³ Ğ´Ğ»Ñ {len(resource_to_metric_ids)} Ñ€ĞµÑÑƒÑ€ÑĞ¾Ğ²")
    print()
    
    return resource_to_metric_ids

def step4_save_mapping(resource_to_metric_ids: dict, output_file: str = "resource_metric_mapping_real.py"):
    """Ğ¨Ğ°Ğ³ 4: Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğµ Ğ¼Ğ°Ğ¿Ğ¿Ğ¸Ğ½Ğ³Ğ° Ğ² Ñ„Ğ°Ğ¹Ğ»"""
    print("="*80)
    print("ğŸ’¾ Ğ¨ĞĞ“ 4: Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğµ Ğ¼Ğ°Ğ¿Ğ¿Ğ¸Ğ½Ğ³Ğ° Ğ² Ñ„Ğ°Ğ¹Ğ»")
    print("="*80)
    
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write('#!/usr/bin/env python3\n')
        f.write('"""\n')
        f.write('ĞœĞ°Ğ¿Ğ¿Ğ¸Ğ½Ğ³ Ñ€ĞµÑÑƒÑ€ÑĞ¾Ğ² Ğ¸ Ğ¼ĞµÑ‚Ñ€Ğ¸Ğº Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ğ Ğ•ĞĞ›Ğ¬ĞĞ«Ğ¥ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ….\n')
        f.write('ĞĞ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸ ÑĞ³ĞµĞ½ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½ Ğ¸Ğ· CSV Ñ„Ğ°Ğ¹Ğ»Ğ°.\n')
        f.write('"""\n\n')
        
        f.write('# ĞœĞ°Ğ¿Ğ¿Ğ¸Ğ½Ğ³ ID Ñ€ĞµÑÑƒÑ€ÑĞ¾Ğ² â†’ Ğ½Ğ°Ğ·Ğ²Ğ°Ğ½Ğ¸Ñ\n')
        f.write('RESOURCE_MAPPING = {\n')
        for resource_id in sorted(resource_to_metric_ids.keys()):
            # Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ resource_id ĞºĞ°Ğº ĞµÑÑ‚ÑŒ, ĞµÑĞ»Ğ¸ Ğ¾Ğ½ ÑĞ¾Ğ²Ğ¿Ğ°Ğ´Ğ°ĞµÑ‚ Ñ Ğ½Ğ°Ğ·Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼
            resource_name = RESOURCE_NAME_DICT.get(resource_id, resource_id)
            f.write(f'    "{resource_id}": "{resource_name}",\n')
        f.write('}\n\n')
        
        f.write('# ĞœĞ°Ğ¿Ğ¿Ğ¸Ğ½Ğ³ ID Ğ¼ĞµÑ‚Ñ€Ğ¸Ğº â†’ Ğ½Ğ°Ğ·Ğ²Ğ°Ğ½Ğ¸Ñ\n')
        f.write('METRIC_MAPPING = {\n')
        
        # Ğ¡Ğ¾Ğ±Ğ¸Ñ€Ğ°ĞµĞ¼ Ğ²ÑĞµ ÑƒĞ½Ğ¸ĞºĞ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ¸
        all_metric_ids = set()
        for metric_ids in resource_to_metric_ids.values():
            all_metric_ids.update(metric_ids)
        
        for metric_id in sorted(all_metric_ids):
            metric_name = METRIC_NAME_DICT.get(metric_id, f"Unknown_{metric_id}")
            # Ğ­ĞºÑ€Ğ°Ğ½Ğ¸Ñ€ÑƒĞµĞ¼ ĞºĞ°Ğ²Ñ‹Ñ‡ĞºĞ¸ Ğ² Ğ½Ğ°Ğ·Ğ²Ğ°Ğ½Ğ¸Ğ¸ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ¸
            metric_name = metric_name.replace('"', '\\"')
            f.write(f'    "{metric_id}": "{metric_name}",\n')
        f.write('}\n\n')
        
        f.write('# ĞœĞ°Ğ¿Ğ¿Ğ¸Ğ½Ğ³: Ğ ĞµÑÑƒÑ€Ñ â†’ Ğ¡Ğ¿Ğ¸ÑĞ¾Ğº Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½Ğ¸Ğ¼Ñ‹Ñ… Ğ¼ĞµÑ‚Ñ€Ğ¸Ğº (ĞĞ ĞĞ¡ĞĞĞ’Ğ• Ğ Ğ•ĞĞ›Ğ¬ĞĞ«Ğ¥ Ğ”ĞĞĞĞ«Ğ¥)\n')
        f.write('RESOURCE_TO_METRICS = {\n')
        for resource_id in sorted(resource_to_metric_ids.keys()):
            metric_ids = resource_to_metric_ids[resource_id]
            f.write(f'    "{resource_id}": [  # {RESOURCE_NAME_DICT.get(resource_id, "Unknown")}\n')
            
            # Ğ“Ñ€ÑƒĞ¿Ğ¿Ğ¸Ñ€ÑƒĞµĞ¼ Ğ¿Ğ¾ 10 Ğ¼ĞµÑ‚Ñ€Ğ¸Ğº Ğ² ÑÑ‚Ñ€Ğ¾ĞºÑƒ
            for i in range(0, len(metric_ids), 10):
                chunk = metric_ids[i:i+10]
                metric_list = ', '.join(f'"{m}"' for m in chunk)
                f.write(f'        {metric_list},\n')
            
            f.write('    ],\n')
        f.write('}\n\n')
        
        f.write('# Ğ¡Ğ¿Ğ¸ÑĞ¾Ğº Ñ€ĞµÑÑƒÑ€ÑĞ¾Ğ² Ğ¿Ğ¾ ÑƒĞ¼Ğ¾Ğ»Ñ‡Ğ°Ğ½Ğ¸Ñ\n')
        f.write('DEFAULT_RESOURCES = [\n')
        for resource_id in sorted(resource_to_metric_ids.keys()):
            f.write(f'    "{resource_id}",  # {RESOURCE_NAME_DICT.get(resource_id, "Unknown")}\n')
        f.write(']\n')
    
    print(f"   âœ… ĞœĞ°Ğ¿Ğ¿Ğ¸Ğ½Ğ³ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½: {output_file}")
    print()
    
    # Ğ’Ñ‹Ğ²Ğ¾Ğ´Ğ¸Ğ¼ ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºÑƒ
    total_metrics = sum(len(ids) for ids in resource_to_metric_ids.values())
    print(f"   ğŸ“Š Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ°:")
    print(f"      â€¢ Ğ ĞµÑÑƒÑ€ÑĞ¾Ğ²: {len(resource_to_metric_ids)}")
    print(f"      â€¢ Ğ£Ğ½Ğ¸ĞºĞ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ¼ĞµÑ‚Ñ€Ğ¸Ğº: {len(all_metric_ids)}")
    print(f"      â€¢ Ğ’ÑĞµĞ³Ğ¾ ĞºĞ¾Ğ¼Ğ±Ğ¸Ğ½Ğ°Ñ†Ğ¸Ğ¹: {total_metrics}")
    print()

def step5_generate_dashboard():
    """Ğ¨Ğ°Ğ³ 5: Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ´Ğ°ÑˆĞ±Ğ¾Ñ€Ğ´Ğ°"""
    print("="*80)
    print("ğŸ“ˆ Ğ¨ĞĞ“ 5: Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ´Ğ°ÑˆĞ±Ğ¾Ñ€Ğ´Ğ° Grafana")
    print("="*80)
    
    print("   â†’ Ğ—Ğ°Ğ¿ÑƒÑĞº Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¾Ñ€Ğ° Ğ´Ğ°ÑˆĞ±Ğ¾Ñ€Ğ´Ğ°...")
    
    # Ğ—Ğ°Ğ¿ÑƒÑĞºĞ°ĞµĞ¼ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¾Ñ€ Ğ´Ğ°ÑˆĞ±Ğ¾Ñ€Ğ´Ğ°
    cmd = ["python3", "generate_dashboard_real.py"]
    
    result = subprocess.run(cmd, capture_output=True, text=True)
    
    if result.returncode != 0:
        print(f"   âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸:")
        print(result.stderr)
        sys.exit(1)
    
    print(result.stdout)
    print()

def main():
    """Ğ“Ğ»Ğ°Ğ²Ğ½Ğ°Ñ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ"""
    print()
    print("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
    print("â•‘                                                                â•‘")
    print("â•‘   ğŸ“Š ĞŸĞĞ¡Ğ¢Ğ ĞĞ•ĞĞ˜Ğ• Ğ”ĞĞ¨Ğ‘ĞĞ Ğ”Ğ ĞĞ ĞĞ¡ĞĞĞ’Ğ• Ğ Ğ•ĞĞ›Ğ¬ĞĞ«Ğ¥ Ğ”ĞĞĞĞ«Ğ¥            â•‘")
    print("â•‘                                                                â•‘")
    print("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
    print()
    
    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ğ½Ğ°Ğ»Ğ¸Ñ‡Ğ¸Ğµ Ğ²Ñ…Ğ¾Ğ´Ğ½Ğ¾Ğ³Ğ¾ Ñ„Ğ°Ğ¹Ğ»Ğ°
    input_zip = "Data2csv/logs/Storage_History_Performance_Files (1).zip"
    
    if not Path(input_zip).exists():
        print(f"âŒ Ğ¤Ğ°Ğ¹Ğ» Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½: {input_zip}")
        print()
        print("Ğ£ĞºĞ°Ğ¶Ğ¸Ñ‚Ğµ Ğ¿ÑƒÑ‚ÑŒ Ğº ZIP Ğ°Ñ€Ñ…Ğ¸Ğ²Ñƒ:")
        input_zip = input("> ").strip()
        
        if not Path(input_zip).exists():
            print(f"âŒ Ğ¤Ğ°Ğ¹Ğ» Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½: {input_zip}")
            sys.exit(1)
    
    print(f"ğŸ“ Ğ’Ñ…Ğ¾Ğ´Ğ½Ğ¾Ğ¹ Ñ„Ğ°Ğ¹Ğ»: {input_zip}")
    print()
    
    # Ğ’Ñ‹Ğ¿Ğ¾Ğ»Ğ½ÑĞµĞ¼ Ğ²ÑĞµ ÑˆĞ°Ğ³Ğ¸
    csv_file = step1_parse_with_all_metrics(input_zip)
    resource_metrics = step2_extract_unique_combinations(csv_file)
    resource_to_metric_ids = step3_create_metric_mapping(resource_metrics)
    step4_save_mapping(resource_to_metric_ids)
    step5_generate_dashboard()
    
    # Ğ˜Ñ‚Ğ¾Ğ³
    print("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
    print("â•‘                                                                â•‘")
    print("â•‘            âœ… Ğ’Ğ¡Ğ• Ğ¨ĞĞ“Ğ˜ Ğ’Ğ«ĞŸĞĞ›ĞĞ•ĞĞ« Ğ£Ğ¡ĞŸĞ•Ğ¨ĞĞ!                      â•‘")
    print("â•‘                                                                â•‘")
    print("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
    print()
    print("ğŸ“ Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ñ„Ğ°Ğ¹Ğ»Ñ‹:")
    print("   â€¢ resource_metric_mapping_real.py - ĞœĞ°Ğ¿Ğ¿Ğ¸Ğ½Ğ³ Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…")
    print("   â€¢ grafana/provisioning/dashboards/Huawei-OceanStor-Real-Data.json")
    print()
    print("ğŸš€ Ğ¡Ğ»ĞµĞ´ÑƒÑÑ‰Ğ¸Ğµ ÑˆĞ°Ğ³Ğ¸:")
    print("   1. Ğ˜Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ğ¸Ñ€ÑƒĞ¹Ñ‚Ğµ CSV Ğ² VictoriaMetrics:")
    print("      python3 csv2vm_parallel.py", csv_file)
    print()
    print("   2. ĞÑ‚ĞºÑ€Ğ¾Ğ¹Ñ‚Ğµ Grafana: http://localhost:3000")
    print("   3. ĞĞ°Ğ¹Ğ´Ğ¸Ñ‚Ğµ Ğ´Ğ°ÑˆĞ±Ğ¾Ñ€Ğ´: 'Huawei OceanStor - Real Data'")
    print()

if __name__ == "__main__":
    main()

