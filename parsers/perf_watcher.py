#!/usr/bin/env python3
"""
PERF WATCHER: –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∏ –ø–∞—Ä—Å–∏–Ω–≥ Performance Dumps

–ú–æ–Ω–∏—Ç–æ—Ä–∏—Ç –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é —Å SFTP dumps –∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø–∞—Ä—Å–∏—Ç –Ω–æ–≤—ã–µ .tgz —Ñ–∞–π–ª—ã,
–æ—Ç–ø—Ä–∞–≤–ª—è—è –º–µ—Ç—Ä–∏–∫–∏ –≤ VictoriaMetrics.

–û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏:
- Watchdog + polling hybrid –¥–ª—è –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏
- –ó–∞–¥–µ—Ä–∂–∫–∞ –ø–µ—Ä–µ–¥ –æ–±—Ä–∞–±–æ—Ç–∫–æ–π (–∂–¥—ë–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –∑–∞–≥—Ä—É–∑–∫–∏ –ø–æ SFTP)
- –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏ —Ä–∞–∑–º–µ—Ä–∞ —Ñ–∞–π–ª–∞
- Retry –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö
- –£–¥–∞–ª–µ–Ω–∏–µ —Ñ–∞–π–ª–æ–≤ –ø–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
- Graceful shutdown

–ó–∞–ø—É—Å–∫:
    python -m parsers.perf_watcher
    
–ò–ª–∏ —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏:
    python -m parsers.perf_watcher --watch-dir /data/perf-dumps/dumps --vm-url http://localhost:8428
"""

import sys
import os
import re
import time
import signal
import logging
import threading
import tarfile
import shutil
from pathlib import Path
from queue import Queue, Empty
from datetime import datetime
from typing import Optional, Set
from dataclasses import dataclass, field

import requests
from watchdog.observers import Observer
from watchdog.events import FileSystemEventHandler, FileCreatedEvent

# –ò–º–ø–æ—Ä—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –º–æ–¥—É–ª–µ–π –ø–∞—Ä—Å–∏–Ω–≥–∞
try:
    from parsers.streaming_pipeline import (
        stream_prometheus_metrics,
        send_batch_to_vm,
        extract_serial_from_filename,
        BATCH_SIZE as DEFAULT_BATCH_SIZE,
    )
    from parsers.dictionaries import METRIC_NAME_DICT, RESOURCE_NAME_DICT
except ImportError:
    # –ó–∞–ø—É—Å–∫ –Ω–∞–ø—Ä—è–º—É—é
    sys.path.insert(0, str(Path(__file__).parent.parent))
    from parsers.streaming_pipeline import (
        stream_prometheus_metrics,
        send_batch_to_vm,
        extract_serial_from_filename,
        BATCH_SIZE as DEFAULT_BATCH_SIZE,
    )
    from parsers.dictionaries import METRIC_NAME_DICT, RESOURCE_NAME_DICT

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
VM_URL = os.getenv("VM_URL", "http://victoriametrics:8428")
VM_IMPORT_URL = os.getenv("VM_IMPORT_URL", f"{VM_URL}/api/v1/import/prometheus")
WATCH_DIR = os.getenv("WATCH_DIR", "/data/perf-dumps/dumps")
FILE_WAIT_SECONDS = int(os.getenv("FILE_WAIT_SECONDS", "30"))
DELETE_AFTER_PROCESS = os.getenv("DELETE_AFTER_PROCESS", "true").lower() == "true"
BATCH_SIZE = int(os.getenv("BATCH_SIZE", str(DEFAULT_BATCH_SIZE)))
MAX_RETRIES = int(os.getenv("MAX_RETRIES", "3"))
POLL_INTERVAL_SECONDS = int(os.getenv("POLL_INTERVAL_SECONDS", "60"))
FILE_STABILITY_CHECK_SECONDS = int(os.getenv("FILE_STABILITY_CHECK_SECONDS", "5"))

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
LOG_DIR = Path("/app/logs") if Path("/app").exists() else Path("logs")
LOG_DIR.mkdir(parents=True, exist_ok=True)

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(LOG_DIR / 'perf_watcher.log', mode='a', encoding='utf-8'),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)


@dataclass
class FileTask:
    """–ó–∞–¥–∞—á–∞ –Ω–∞ –æ–±—Ä–∞–±–æ—Ç–∫—É —Ñ–∞–π–ª–∞."""
    path: Path
    added_time: float = field(default_factory=time.time)
    retries: int = 0
    
    @property
    def ready_time(self) -> float:
        """–í—Ä–µ–º—è –∫–æ–≥–¥–∞ —Ñ–∞–π–ª –±—É–¥–µ—Ç –≥–æ—Ç–æ–≤ –∫ –æ–±—Ä–∞–±–æ—Ç–∫–µ."""
        return self.added_time + FILE_WAIT_SECONDS


class TgzFileHandler(FileSystemEventHandler):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ —Å–æ–±—ã—Ç–∏–π —Ñ–∞–π–ª–æ–≤–æ–π —Å–∏—Å—Ç–µ–º—ã –¥–ª—è .tgz —Ñ–∞–π–ª–æ–≤."""
    
    def __init__(self, task_queue: Queue, processing_files: Set[str]):
        super().__init__()
        self.task_queue = task_queue
        self.processing_files = processing_files
    
    def on_created(self, event):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–æ–±—ã—Ç–∏—è —Å–æ–∑–¥–∞–Ω–∏—è —Ñ–∞–π–ª–∞."""
        if event.is_directory:
            return
            
        path = Path(event.src_path)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —ç—Ç–æ .tgz —Ñ–∞–π–ª —Å performance –¥–∞–Ω–Ω—ã–º–∏
        if not path.suffix == '.tgz':
            return
        if not path.name.startswith('PerfData_'):
            return
            
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —Ñ–∞–π–ª –Ω–µ –≤ –æ–±—Ä–∞–±–æ—Ç–∫–µ
        if str(path) in self.processing_files:
            return
            
        logger.info(f"üì• –û–±–Ω–∞—Ä—É–∂–µ–Ω –Ω–æ–≤—ã–π —Ñ–∞–π–ª: {path.name}")
        self.task_queue.put(FileTask(path=path))


class PerfWatcher:
    """
    –û—Å–Ω–æ–≤–Ω–æ–π –∫–ª–∞—Å—Å watcher —Å–µ—Ä–≤–∏—Å–∞.
    
    –ú–æ–Ω–∏—Ç–æ—Ä–∏—Ç –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –Ω–æ–≤—ã–µ .tgz —Ñ–∞–π–ª—ã.
    """
    
    def __init__(
        self,
        watch_dir: str = WATCH_DIR,
        vm_import_url: str = VM_IMPORT_URL,
        batch_size: int = BATCH_SIZE,
        delete_after_process: bool = DELETE_AFTER_PROCESS,
        max_retries: int = MAX_RETRIES,
    ):
        self.watch_dir = Path(watch_dir)
        self.vm_import_url = vm_import_url
        self.batch_size = batch_size
        self.delete_after_process = delete_after_process
        self.max_retries = max_retries
        
        # –û—á–µ—Ä–µ–¥—å –∑–∞–¥–∞—á –Ω–∞ –æ–±—Ä–∞–±–æ—Ç–∫—É
        self.task_queue: Queue[FileTask] = Queue()
        
        # –§–∞–π–ª—ã –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏ (–¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è –¥—É–±–ª–µ–π)
        self.processing_files: Set[str] = set()
        
        # –û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã –≤ —Ç–µ–∫—É—â–µ–π —Å–µ—Å—Å–∏–∏ (–¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏)
        self.processed_count = 0
        self.failed_count = 0
        self.total_metrics_sent = 0
        
        # –§–ª–∞–≥ –¥–ª—è graceful shutdown
        self.shutdown_event = threading.Event()
        
        # Watchdog observer
        self.observer: Optional[Observer] = None
        
        # –í—Å–µ –∏–∑–≤–µ—Å—Ç–Ω—ã–µ —Ä–µ—Å—É—Ä—Å—ã –∏ –º–µ—Ç—Ä–∏–∫–∏
        self.resources = list(RESOURCE_NAME_DICT.keys())
        self.metrics = list(METRIC_NAME_DICT.keys())
        
        logger.info(f"üìä –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(self.metrics)} –º–µ—Ç—Ä–∏–∫, {len(self.resources)} —Ä–µ—Å—É—Ä—Å–æ–≤")
    
    def start(self):
        """–ó–∞–ø—É—Å–∫ watcher —Å–µ—Ä–≤–∏—Å–∞."""
        logger.info("=" * 80)
        logger.info("üöÄ PERF WATCHER STARTED")
        logger.info("=" * 80)
        logger.info(f"Watch directory:  {self.watch_dir}")
        logger.info(f"VM Import URL:    {self.vm_import_url}")
        logger.info(f"File wait time:   {FILE_WAIT_SECONDS}s")
        logger.info(f"Delete after:     {self.delete_after_process}")
        logger.info(f"Batch size:       {self.batch_size:,}")
        logger.info(f"Max retries:      {self.max_retries}")
        logger.info("=" * 80)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å VictoriaMetrics
        if not self._check_vm_health():
            logger.error("‚ùå VictoriaMetrics –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω!")
            return False
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
        if not self.watch_dir.exists():
            logger.error(f"‚ùå –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç: {self.watch_dir}")
            return False
        
        # –†–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ —Å–∏–≥–Ω–∞–ª–æ–≤
        signal.signal(signal.SIGTERM, self._signal_handler)
        signal.signal(signal.SIGINT, self._signal_handler)
        
        # –°–∫–∞–Ω–∏—Ä—É–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ —Ñ–∞–π–ª—ã
        self._scan_existing_files()
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º watchdog
        self._start_watchdog()
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º worker –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—á–µ—Ä–µ–¥–∏
        worker_thread = threading.Thread(target=self._process_queue_worker, daemon=True)
        worker_thread.start()
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–æ–µ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ (backup –¥–ª—è watchdog)
        poll_thread = threading.Thread(target=self._poll_worker, daemon=True)
        poll_thread.start()
        
        # –û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª (–∂–¥—ë–º shutdown)
        try:
            while not self.shutdown_event.is_set():
                self.shutdown_event.wait(timeout=1.0)
        except KeyboardInterrupt:
            pass
        
        self._shutdown()
        return True
    
    def _signal_handler(self, signum, frame):
        """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ —Å–∏–≥–Ω–∞–ª–æ–≤ –¥–ª—è graceful shutdown."""
        sig_name = signal.Signals(signum).name
        logger.info(f"‚ö†Ô∏è  –ü–æ–ª—É—á–µ–Ω —Å–∏–≥–Ω–∞–ª {sig_name}, –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã...")
        self.shutdown_event.set()
    
    def _check_vm_health(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ VictoriaMetrics."""
        try:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º base URL –∏–∑ import URL
            base_url = self.vm_import_url.rsplit('/api/', 1)[0]
            response = requests.get(f"{base_url}/-/healthy", timeout=5)
            if response.status_code == 200:
                logger.info("‚úÖ VictoriaMetrics –¥–æ—Å—Ç—É–ø–µ–Ω")
                return True
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–≤–µ—Ä–∏—Ç—å VM health: {e}")
        
        # –ü—Ä–æ–±—É–µ–º –æ—Ç–ø—Ä–∞–≤–∏—Ç—å —Ç–µ—Å—Ç–æ–≤—É—é –º–µ—Ç—Ä–∏–∫—É
        try:
            test_metric = 'perf_watcher_health{status="ok"} 1\n'
            response = requests.post(self.vm_import_url, data=test_metric.encode(), timeout=5)
            if response.status_code in (200, 204):
                logger.info("‚úÖ VictoriaMetrics –¥–æ—Å—Ç—É–ø–µ–Ω (–ø—Ä–æ–≤–µ—Ä–∫–∞ —á–µ—Ä–µ–∑ import)")
                return True
        except Exception as e:
            logger.error(f"‚ùå VictoriaMetrics –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {e}")
        
        return False
    
    def _scan_existing_files(self):
        """–°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö .tgz —Ñ–∞–π–ª–æ–≤ –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ."""
        logger.info("üîç –°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —Ñ–∞–π–ª–æ–≤...")
        
        # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ .tgz —Ñ–∞–π–ª—ã —Ä–µ–∫—É—Ä—Å–∏–≤–Ω–æ
        tgz_files = list(self.watch_dir.rglob("PerfData_*.tgz"))
        
        if not tgz_files:
            logger.info("üìÅ –ù–æ–≤—ã—Ö —Ñ–∞–π–ª–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
            return
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏ –º–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏–∏ (—Å—Ç–∞—Ä—ã–µ –ø–µ—Ä–≤—ã–º–∏)
        tgz_files.sort(key=lambda f: f.stat().st_mtime)
        
        logger.info(f"üìÅ –ù–∞–π–¥–µ–Ω–æ {len(tgz_files)} —Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
        
        # –î–æ–±–∞–≤–ª—è–µ–º –≤ –æ—á–µ—Ä–µ–¥—å —Å –Ω—É–ª–µ–≤–æ–π –∑–∞–¥–µ—Ä–∂–∫–æ–π (—Ñ–∞–π–ª—ã —É–∂–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã)
        for tgz_file in tgz_files:
            task = FileTask(path=tgz_file, added_time=0)  # –°—Ä–∞–∑—É –≥–æ—Ç–æ–≤ –∫ –æ–±—Ä–∞–±–æ—Ç–∫–µ
            self.task_queue.put(task)
    
    def _start_watchdog(self):
        """–ó–∞–ø—É—Å–∫ watchdog observer."""
        event_handler = TgzFileHandler(self.task_queue, self.processing_files)
        
        self.observer = Observer()
        # –†–µ–∫—É—Ä—Å–∏–≤–Ω–æ–µ –Ω–∞–±–ª—é–¥–µ–Ω–∏–µ –∑–∞ –≤—Å–µ–º–∏ –ø–æ–¥–ø–∞–ø–∫–∞–º–∏
        self.observer.schedule(event_handler, str(self.watch_dir), recursive=True)
        self.observer.start()
        
        logger.info(f"üëÅÔ∏è  Watchdog –∑–∞–ø—É—â–µ–Ω –¥–ª—è {self.watch_dir}")
    
    def _poll_worker(self):
        """–ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–æ–µ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ (backup –¥–ª—è watchdog)."""
        while not self.shutdown_event.is_set():
            self.shutdown_event.wait(timeout=POLL_INTERVAL_SECONDS)
            
            if self.shutdown_event.is_set():
                break
            
            # –°–∫–∞–Ω–∏—Ä—É–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
            try:
                tgz_files = list(self.watch_dir.rglob("PerfData_*.tgz"))
                
                for tgz_file in tgz_files:
                    # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Ñ–∞–π–ª—ã –≤ –æ–±—Ä–∞–±–æ—Ç–∫–µ
                    if str(tgz_file) in self.processing_files:
                        continue
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–µ –¥–æ–±–∞–≤–ª–µ–Ω –ª–∏ —É–∂–µ –≤ –æ—á–µ—Ä–µ–¥—å
                    # (–ø—Ä–æ—Å—Ç–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —á–µ—Ä–µ–∑ processing_files)
                    task = FileTask(path=tgz_file, added_time=0)
                    self.task_queue.put(task)
                    
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–∏: {e}")
    
    def _process_queue_worker(self):
        """Worker –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—á–µ—Ä–µ–¥–∏ —Ñ–∞–π–ª–æ–≤."""
        while not self.shutdown_event.is_set():
            try:
                # –ü–æ–ª—É—á–∞–µ–º –∑–∞–¥–∞—á—É –∏–∑ –æ—á–µ—Ä–µ–¥–∏ —Å —Ç–∞–π–º–∞—É—Ç–æ–º
                task = self.task_queue.get(timeout=1.0)
            except Empty:
                continue
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º shutdown
            if self.shutdown_event.is_set():
                # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∑–∞–¥–∞—á—É –≤ –æ—á–µ—Ä–µ–¥—å (–±—É–¥–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∞–Ω–∞ –ø—Ä–∏ —Å–ª–µ–¥—É—é—â–µ–º –∑–∞–ø—É—Å–∫–µ)
                self.task_queue.put(task)
                break
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–∞–π–ª –Ω–µ –≤ –æ–±—Ä–∞–±–æ—Ç–∫–µ
            if str(task.path) in self.processing_files:
                continue
            
            # –ñ–¥—ë–º –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ —Ñ–∞–π–ª–∞ (–∑–∞–¥–µ—Ä–∂–∫–∞ –ø–æ—Å–ª–µ –ø–æ—è–≤–ª–µ–Ω–∏—è)
            wait_time = task.ready_time - time.time()
            if wait_time > 0:
                logger.debug(f"‚è≥ –û–∂–∏–¥–∞–Ω–∏–µ {wait_time:.1f}s –¥–ª—è {task.path.name}")
                # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –≤ –æ—á–µ—Ä–µ–¥—å –∏ –∂–¥—ë–º
                self.task_queue.put(task)
                time.sleep(min(wait_time, 5.0))  # –ù–µ –∂–¥—ë–º —Å–ª–∏—à–∫–æ–º –¥–æ–ª–≥–æ –∑–∞ —Ä–∞–∑
                continue
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —Ñ–∞–π–ª —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
            if not task.path.exists():
                logger.warning(f"‚ö†Ô∏è  –§–∞–π–ª –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç: {task.path}")
                continue
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å —Ä–∞–∑–º–µ—Ä–∞ —Ñ–∞–π–ª–∞
            if not self._check_file_stability(task.path):
                logger.debug(f"‚è≥ –§–∞–π–ª –µ—â—ë –∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è: {task.path.name}")
                task.added_time = time.time()  # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Ç–∞–π–º–µ—Ä
                self.task_queue.put(task)
                continue
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ñ–∞–π–ª
            self.processing_files.add(str(task.path))
            
            try:
                success = self._process_file(task.path)
                
                if success:
                    self.processed_count += 1
                    
                    if self.delete_after_process:
                        try:
                            task.path.unlink()
                            logger.info(f"üóëÔ∏è  –£–¥–∞–ª—ë–Ω: {task.path.name}")
                        except Exception as e:
                            logger.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å {task.path}: {e}")
                else:
                    # Retry
                    task.retries += 1
                    if task.retries < self.max_retries:
                        logger.warning(f"‚ö†Ô∏è  Retry {task.retries}/{self.max_retries} –¥–ª—è {task.path.name}")
                        task.added_time = time.time()  # –î–æ–±–∞–≤–ª—è–µ–º –∑–∞–¥–µ—Ä–∂–∫—É –ø–µ—Ä–µ–¥ retry
                        self.task_queue.put(task)
                    else:
                        logger.error(f"‚ùå –ü—Ä–µ–≤—ã—à–µ–Ω–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ø—ã—Ç–æ–∫ –¥–ª—è {task.path.name}")
                        self.failed_count += 1
                        
            finally:
                self.processing_files.discard(str(task.path))
    
    def _check_file_stability(self, path: Path) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —á—Ç–æ —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ –Ω–µ –º–µ–Ω—è–µ—Ç—Å—è (–∑–∞–≥—Ä—É–∑–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞)."""
        try:
            size1 = path.stat().st_size
            time.sleep(FILE_STABILITY_CHECK_SECONDS)
            size2 = path.stat().st_size
            return size1 == size2 and size1 > 0
        except Exception:
            return False
    
    def _process_file(self, tgz_path: Path) -> bool:
        """
        –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–≥–æ .tgz —Ñ–∞–π–ª–∞.
        
        Returns:
            True –µ—Å–ª–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ —É—Å–ø–µ—à–Ω–∞, False –ø—Ä–∏ –æ—à–∏–±–∫–µ
        """
        logger.info(f"‚öôÔ∏è  –û–±—Ä–∞–±–æ—Ç–∫–∞: {tgz_path.name}")
        start_time = time.time()
        
        # –°–æ–∑–¥–∞—ë–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è —Ä–∞—Å–ø–∞–∫–æ–≤–∫–∏
        temp_dir = Path(f"/tmp/perf_watcher_{os.getpid()}_{time.time()}")
        temp_dir.mkdir(parents=True, exist_ok=True)
        
        try:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å–µ—Ä–∏–π–Ω—ã–π –Ω–æ–º–µ—Ä –∏–∑ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
            array_sn = extract_serial_from_filename(tgz_path.name)
            
            # –†–∞—Å–ø–∞–∫–æ–≤—ã–≤–∞–µ–º .tgz
            dat_file = self._extract_tgz(tgz_path, temp_dir)
            if not dat_file:
                logger.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞–∫–æ–≤–∞—Ç—å {tgz_path.name}")
                return False
            
            # –ü–∞—Ä—Å–∏–º –∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
            metrics_sent = 0
            batches_sent = 0
            batch = []
            
            for metric_line in stream_prometheus_metrics(
                dat_file, array_sn, self.resources, self.metrics
            ):
                batch.append(metric_line)
                
                if len(batch) >= self.batch_size:
                    if send_batch_to_vm(batch, self.vm_import_url):
                        metrics_sent += len(batch)
                        batches_sent += 1
                        batch = []
                    else:
                        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ batch –≤ VM")
                        return False
            
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –æ—Å—Ç–∞—Ç–æ–∫
            if batch:
                if send_batch_to_vm(batch, self.vm_import_url):
                    metrics_sent += len(batch)
                    batches_sent += 1
                else:
                    logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ batch –≤ VM")
                    return False
            
            elapsed = time.time() - start_time
            rate = metrics_sent / elapsed if elapsed > 0 else 0
            
            self.total_metrics_sent += metrics_sent
            
            logger.info(
                f"‚úÖ {tgz_path.name}: {metrics_sent:,} –º–µ—Ç—Ä–∏–∫ –∑–∞ {elapsed:.1f}s "
                f"({rate:,.0f} m/s) | SN: {array_sn}"
            )
            
            return True
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ {tgz_path.name}: {e}", exc_info=True)
            return False
            
        finally:
            # Cleanup –≤—Ä–µ–º–µ–Ω–Ω–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
            if temp_dir.exists():
                try:
                    shutil.rmtree(temp_dir)
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å temp dir: {e}")
    
    def _extract_tgz(self, tgz_path: Path, temp_dir: Path) -> Optional[Path]:
        """
        –†–∞—Å–ø–∞–∫–æ–≤–∫–∞ .tgz —Ñ–∞–π–ª–∞.
        
        Returns:
            Path –∫ .dat —Ñ–∞–π–ª—É –∏–ª–∏ None –ø—Ä–∏ –æ—à–∏–±–∫–µ
        """
        try:
            with tarfile.open(tgz_path, 'r:gz') as tar:
                names = tar.getnames()
                
                if len(names) != 1:
                    logger.warning(f"‚ö†Ô∏è  –ù–µ–æ–∂–∏–¥–∞–Ω–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∞–π–ª–æ–≤ –≤ –∞—Ä—Ö–∏–≤–µ: {len(names)}")
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø–µ—Ä–≤—ã–π —Ñ–∞–π–ª (–æ–±—ã—á–Ω–æ .dat)
                tar.extractall(temp_dir)
                
                # –ù–∞—Ö–æ–¥–∏–º .dat —Ñ–∞–π–ª
                dat_files = list(temp_dir.glob("*.dat"))
                if dat_files:
                    return dat_files[0]
                
                # –ï—Å–ª–∏ –Ω–µ—Ç .dat, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø–µ—Ä–≤—ã–π –∏–∑–≤–ª–µ—á—ë–Ω–Ω—ã–π —Ñ–∞–π–ª
                extracted = temp_dir / names[0]
                if extracted.exists():
                    return extracted
                    
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Ä–∞—Å–ø–∞–∫–æ–≤–∫–∏ {tgz_path}: {e}")
        
        return None
    
    def _shutdown(self):
        """Graceful shutdown."""
        logger.info("üõë –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã...")
        
        # –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º watchdog
        if self.observer:
            self.observer.stop()
            self.observer.join(timeout=5.0)
        
        # –í—ã–≤–æ–¥–∏–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        logger.info("=" * 80)
        logger.info("üìä –ò–¢–û–ì–û–í–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê")
        logger.info("=" * 80)
        logger.info(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Ñ–∞–π–ª–æ–≤:  {self.processed_count}")
        logger.info(f"–û—à–∏–±–æ–∫:             {self.failed_count}")
        logger.info(f"–ú–µ—Ç—Ä–∏–∫ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ:  {self.total_metrics_sent:,}")
        logger.info(f"–í –æ—á–µ—Ä–µ–¥–∏:          {self.task_queue.qsize()}")
        logger.info("=" * 80)
        logger.info("üëã Perf Watcher –∑–∞–≤–µ—Ä—à—ë–Ω")


def main():
    """–¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞."""
    import argparse
    
    parser = argparse.ArgumentParser(
        description="Perf Watcher: –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ø–∞—Ä—Å–∏–Ω–≥ Performance Dumps",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
–ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è:
  VM_URL                    VictoriaMetrics URL (default: http://victoriametrics:8428)
  WATCH_DIR                 –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ (default: /data/perf-dumps/dumps)
  FILE_WAIT_SECONDS         –ó–∞–¥–µ—Ä–∂–∫–∞ –ø–µ—Ä–µ–¥ –æ–±—Ä–∞–±–æ—Ç–∫–æ–π (default: 30)
  DELETE_AFTER_PROCESS      –£–¥–∞–ª—è—Ç—å —Ñ–∞–π–ª—ã –ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏ (default: true)
  BATCH_SIZE                –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –º–µ—Ç—Ä–∏–∫ (default: 100000)
  MAX_RETRIES               –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ø—ã—Ç–æ–∫ –ø—Ä–∏ –æ—à–∏–±–∫–µ (default: 3)

–ü—Ä–∏–º–µ—Ä—ã:
  # –ó–∞–ø—É—Å–∫ —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
  python -m parsers.perf_watcher
  
  # –ó–∞–ø—É—Å–∫ —Å —É–∫–∞–∑–∞–Ω–∏–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
  python -m parsers.perf_watcher --watch-dir /data/perf-dumps/dumps
  
  # –ó–∞–ø—É—Å–∫ –±–µ–∑ —É–¥–∞–ª–µ–Ω–∏—è —Ñ–∞–π–ª–æ–≤
  python -m parsers.perf_watcher --no-delete
        """
    )
    
    parser.add_argument(
        '--watch-dir', '-w',
        type=str,
        default=WATCH_DIR,
        help=f'–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ (default: {WATCH_DIR})'
    )
    parser.add_argument(
        '--vm-url',
        type=str,
        default=VM_URL,
        help=f'VictoriaMetrics URL (default: {VM_URL})'
    )
    parser.add_argument(
        '--no-delete',
        action='store_true',
        help='–ù–µ —É–¥–∞–ª—è—Ç—å —Ñ–∞–π–ª—ã –ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏'
    )
    parser.add_argument(
        '--batch-size',
        type=int,
        default=BATCH_SIZE,
        help=f'–†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –º–µ—Ç—Ä–∏–∫ (default: {BATCH_SIZE})'
    )
    
    args = parser.parse_args()
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º VM import URL
    vm_import_url = f"{args.vm_url}/api/v1/import/prometheus"
    
    # –°–æ–∑–¥–∞—ë–º –∏ –∑–∞–ø—É—Å–∫–∞–µ–º watcher
    watcher = PerfWatcher(
        watch_dir=args.watch_dir,
        vm_import_url=vm_import_url,
        batch_size=args.batch_size,
        delete_after_process=not args.no_delete,
    )
    
    success = watcher.start()
    sys.exit(0 if success else 1)


if __name__ == "__main__":
    main()

