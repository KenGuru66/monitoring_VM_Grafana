#!/usr/bin/env python3
"""
–ü–æ–ª–Ω—ã–π –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π pipeline –æ–±—Ä–∞–±–æ—Ç–∫–∏ Huawei Performance Data.

–í—ã–ø–æ–ª–Ω—è–µ—Ç:
1. –ü–∞—Ä—Å–∏–Ω–≥ .tgz —Ñ–∞–π–ª–æ–≤ –∏–∑ ZIP –∞—Ä—Ö–∏–≤–∞ –≤ CSV (–ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ)
2. –ò–º–ø–æ—Ä—Ç CSV –≤ VictoriaMetrics (–ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ)
3. –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã—Ö CSV —Ñ–∞–π–ª–æ–≤

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
    python3 huawei_to_vm_pipeline.py -i "Data2csv/logs/archive.zip"
"""

import argparse
import subprocess
import sys
import os
import pathlib
import logging
import time
from datetime import datetime
import glob

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('pipeline.log', mode='a', encoding='utf-8'),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)

def run_command(cmd, description):
    """–í—ã–ø–æ–ª–Ω—è–µ—Ç –∫–æ–º–∞–Ω–¥—É –∏ –ª–æ–≥–∏—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏."""
    logger.info(f"{'='*80}")
    logger.info(f"üöÄ {description}")
    logger.info(f"Command: {' '.join(cmd)}")
    logger.info(f"{'='*80}")
    
    start_time = time.time()
    
    try:
        # –ó–∞–ø—É—Å–∫–∞–µ–º –ø—Ä–æ—Ü–µ—Å—Å —Å –ø–æ—Ç–æ–∫–æ–≤—ã–º –≤—ã–≤–æ–¥–æ–º
        process = subprocess.Popen(
            cmd,
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,
            text=True,
            bufsize=1,  # Line buffered
            universal_newlines=True
        )
        
        # –ß–∏—Ç–∞–µ–º –≤—ã–≤–æ–¥ –ø–æ—Å—Ç—Ä–æ—á–Ω–æ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏
        output_lines = []
        for line in process.stdout:
            line = line.rstrip()
            if line:
                logger.info(f"   {line}")
                output_lines.append(line)
        
        # –ñ–¥–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –ø—Ä–æ—Ü–µ—Å—Å–∞
        return_code = process.wait()
        
        elapsed = time.time() - start_time
        
        if return_code == 0:
            logger.info(f"‚úÖ {description} - –£–°–ü–ï–®–ù–û")
            logger.info(f"‚è±Ô∏è  –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {elapsed:.1f} —Å–µ–∫—É–Ω–¥")
            return True, elapsed
        else:
            logger.error(f"‚ùå {description} - –û–®–ò–ë–ö–ê")
            logger.error(f"‚è±Ô∏è  –í—Ä–µ–º—è –¥–æ –æ—à–∏–±–∫–∏: {elapsed:.1f} —Å–µ–∫—É–Ω–¥")
            logger.error(f"–ö–æ–¥ –≤–æ–∑–≤—Ä–∞—Ç–∞: {return_code}")
            return False, elapsed
        
    except Exception as e:
        elapsed = time.time() - start_time
        logger.error(f"‚ùå {description} - –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê")
        logger.error(f"‚è±Ô∏è  –í—Ä–µ–º—è –¥–æ –æ—à–∏–±–∫–∏: {elapsed:.1f} —Å–µ–∫—É–Ω–¥")
        logger.error(f"–û—à–∏–±–∫–∞: {str(e)}")
        return False, elapsed

def main():
    parser = argparse.ArgumentParser(
        description="–ü–æ–ª–Ω—ã–π pipeline: Huawei Performance Data ‚Üí VictoriaMetrics",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
–ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:

  # –ë–∞–∑–æ–≤—ã–π –∑–∞–ø—É—Å–∫
  %(prog)s -i "Data2csv/logs/Storage_History_Performance_Files.zip"
  
  # –° —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º CSV —Ñ–∞–π–ª–æ–≤
  %(prog)s -i "Data2csv/logs/archive.zip" --keep-csv
  
  # –° –Ω–∞—Å—Ç—Ä–æ–π–∫–æ–π –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ workers
  %(prog)s -i "Data2csv/logs/archive.zip" --workers 6
  
  # –° —É–∫–∞–∑–∞–Ω–∏–µ–º URL VictoriaMetrics
  %(prog)s -i "Data2csv/logs/archive.zip" --vm-url "http://victoriametrics:8428/api/v1/import/prometheus"
  
  # –° –ø–∞—Ä—Å–∏–Ω–≥–æ–º –í–°–ï–• –º–µ—Ç—Ä–∏–∫ (–≤–º–µ—Å—Ç–æ DEFAULT —Å–ø–∏—Å–∫–∞)
  %(prog)s -i "Data2csv/logs/archive.zip" --all-metrics

Pipeline –≤—ã–ø–æ–ª–Ω—è–µ—Ç:
  1. –ü–∞—Ä—Å–∏–Ω–≥ .tgz ‚Üí CSV (–ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ, –∞–≤—Ç–æ workers)
  2. –ò–º–ø–æ—Ä—Ç CSV ‚Üí VictoriaMetrics (–ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ, –∞–≤—Ç–æ workers)
  3. –û—á–∏—Å—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        """)
    
    parser.add_argument(
        '-i', '--input',
        type=str,
        required=True,
        help='–ü—É—Ç—å –∫ –≤—Ö–æ–¥–Ω–æ–º—É ZIP –∞—Ä—Ö–∏–≤—É —Å .tgz —Ñ–∞–π–ª–∞–º–∏'
    )
    
    parser.add_argument(
        '-o', '--output-dir',
        type=str,
        default='Data2csv/output',
        help='–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã—Ö CSV —Ñ–∞–π–ª–æ–≤ (default: Data2csv/output)'
    )
    
    parser.add_argument(
        '--vm-url',
        type=str,
        default='http://localhost:8428/api/v1/import/prometheus',
        help='URL endpoint VictoriaMetrics –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞ (default: localhost:8428)'
    )
    
    parser.add_argument(
        '-w', '--workers',
        type=int,
        default=None,
        help='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ worker –ø—Ä–æ—Ü–µ—Å—Å–æ–≤ (default: CPU count - 1)'
    )
    
    parser.add_argument(
        '--keep-csv',
        action='store_true',
        default=False,
        help='–ù–µ —É–¥–∞–ª—è—Ç—å CSV —Ñ–∞–π–ª—ã –ø–æ—Å–ª–µ –∏–º–ø–æ—Ä—Ç–∞'
    )
    
    parser.add_argument(
        '--batch-size',
        type=int,
        default=50000,
        help='–†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞ (default: 50000)'
    )
    
    parser.add_argument(
        '--all-metrics',
        action='store_true',
        default=False,
        help='–ü–∞—Ä—Å–∏—Ç—å –í–°–ï –º–µ—Ç—Ä–∏–∫–∏ –∏ —Ä–µ—Å—É—Ä—Å—ã –∏–∑ METRIC_DICT –∏ RESOURCE_DICT (–≤–º–µ—Å—Ç–æ DEFAULT —Å–ø–∏—Å–∫–æ–≤)'
    )
    
    args = parser.parse_args()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –≤—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
    input_path = pathlib.Path(args.input)
    if not input_path.exists():
        logger.error(f"‚ùå –í—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {args.input}")
        sys.exit(1)
    
    # –ù–∞—á–∞–ª–æ pipeline
    logger.info("‚ïî" + "‚ïê"*78 + "‚ïó")
    logger.info("‚ïë" + " "*78 + "‚ïë")
    logger.info("‚ïë" + "  HUAWEI PERFORMANCE DATA ‚Üí VICTORIAMETRICS PIPELINE".center(78) + "‚ïë")
    logger.info("‚ïë" + " "*78 + "‚ïë")
    logger.info("‚ïö" + "‚ïê"*78 + "‚ïù")
    logger.info("")
    logger.info(f"üìÖ –î–∞—Ç–∞ –∑–∞–ø—É—Å–∫–∞: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    logger.info(f"üìÅ –í—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª: {args.input}")
    logger.info(f"üìÇ –í—ã—Ö–æ–¥–Ω–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {args.output_dir}")
    logger.info(f"üåê VictoriaMetrics URL: {args.vm_url}")
    logger.info(f"üë∑ Workers: {args.workers if args.workers else 'auto (CPU-1)'}")
    logger.info("")
    
    pipeline_start = time.time()
    
    # ========================================================================
    # –≠–¢–ê–ü 1: –ü–ê–†–°–ò–ù–ì
    # ========================================================================
    
    parse_cmd = [
        'python3',
        'Data2csv/Huawei_perf_parser_v0.2_parallel.py',
        '-i', str(input_path),
        '-o', args.output_dir
    ]
    
    if args.workers:
        parse_cmd.extend(['-w', str(args.workers)])
    
    if args.all_metrics:
        parse_cmd.append('--all-metrics')
    
    success, parse_time = run_command(parse_cmd, "–≠–¢–ê–ü 1: –ü–∞—Ä—Å–∏–Ω–≥ .tgz —Ñ–∞–π–ª–æ–≤ –≤ CSV")
    
    if not success:
        logger.error("‚ùå Pipeline –ø—Ä–µ—Ä–≤–∞–Ω –∏–∑-–∑–∞ –æ—à–∏–±–∫–∏ –ø–∞—Ä—Å–∏–Ω–≥–∞")
        sys.exit(1)
    
    # –ò—â–µ–º —Å–æ–∑–¥–∞–Ω–Ω—ã–µ CSV —Ñ–∞–π–ª—ã
    csv_files = glob.glob(os.path.join(args.output_dir, '*.csv'))
    
    if not csv_files:
        logger.error(f"‚ùå CSV —Ñ–∞–π–ª—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ {args.output_dir}")
        sys.exit(1)
    
    logger.info("")
    logger.info(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ CSV —Ñ–∞–π–ª–æ–≤: {len(csv_files)}")
    for csv_file in csv_files:
        size = os.path.getsize(csv_file) / (1024**3)  # GB
        logger.info(f"   üìÑ {os.path.basename(csv_file)} ({size:.2f} GB)")
    logger.info("")
    
    # ========================================================================
    # –≠–¢–ê–ü 2: –ò–ú–ü–û–†–¢ –í VICTORIAMETRICS
    # ========================================================================
    
    total_import_time = 0
    
    for idx, csv_file in enumerate(csv_files, 1):
        import_cmd = [
            'python3',
            'csv2vm_parallel.py',
            csv_file,
            '--url', args.vm_url,
            '--batch', str(args.batch_size)
        ]
        
        if args.workers:
            import_cmd.extend(['--workers', str(args.workers)])
        
        description = f"–≠–¢–ê–ü 2.{idx}: –ò–º–ø–æ—Ä—Ç {os.path.basename(csv_file)} –≤ VictoriaMetrics"
        success, import_time = run_command(import_cmd, description)
        
        if not success:
            logger.error("‚ùå Pipeline –ø—Ä–µ—Ä–≤–∞–Ω –∏–∑-–∑–∞ –æ—à–∏–±–∫–∏ –∏–º–ø–æ—Ä—Ç–∞")
            if not args.keep_csv:
                logger.info("‚ö†Ô∏è  CSV —Ñ–∞–π–ª—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏")
            sys.exit(1)
        
        total_import_time += import_time
    
    # ========================================================================
    # –≠–¢–ê–ü 3: –û–ß–ò–°–¢–ö–ê (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    # ========================================================================
    
    if not args.keep_csv:
        logger.info("")
        logger.info("="*80)
        logger.info("üßπ –≠–¢–ê–ü 3: –û—á–∏—Å—Ç–∫–∞ –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã—Ö CSV —Ñ–∞–π–ª–æ–≤")
        logger.info("="*80)
        
        for csv_file in csv_files:
            try:
                os.remove(csv_file)
                logger.info(f"   ‚úÖ –£–¥–∞–ª—ë–Ω: {os.path.basename(csv_file)}")
            except Exception as e:
                logger.warning(f"   ‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å {csv_file}: {e}")
        
        logger.info("‚úÖ –û—á–∏—Å—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞")
    else:
        logger.info("")
        logger.info("‚ÑπÔ∏è  CSV —Ñ–∞–π–ª—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã (--keep-csv)")
    
    # ========================================================================
    # –ò–¢–û–ì–ò
    # ========================================================================
    
    total_time = time.time() - pipeline_start
    
    logger.info("")
    logger.info("‚ïî" + "‚ïê"*78 + "‚ïó")
    logger.info("‚ïë" + " "*78 + "‚ïë")
    logger.info("‚ïë" + "  ‚úÖ PIPELINE –ó–ê–í–ï–†–®–Å–ù –£–°–ü–ï–®–ù–û!".center(78) + "‚ïë")
    logger.info("‚ïë" + " "*78 + "‚ïë")
    logger.info("‚ïö" + "‚ïê"*78 + "‚ïù")
    logger.info("")
    logger.info("üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
    logger.info(f"   üìà –≠—Ç–∞–ø 1 (–ü–∞—Ä—Å–∏–Ω–≥):  {parse_time:.1f} —Å–µ–∫")
    logger.info(f"   üìà –≠—Ç–∞–ø 2 (–ò–º–ø–æ—Ä—Ç):   {total_import_time:.1f} —Å–µ–∫")
    logger.info(f"   ‚è±Ô∏è  –û–±—â–µ–µ –≤—Ä–µ–º—è:      {total_time:.1f} —Å–µ–∫ ({total_time/60:.1f} –º–∏–Ω)")
    logger.info(f"   üìÅ CSV —Ñ–∞–π–ª–æ–≤:        {len(csv_files)}")
    logger.info(f"   üíæ –•—Ä–∞–Ω–µ–Ω–∏–µ CSV:      {'–î–∞' if args.keep_csv else '–ù–µ—Ç (—É–¥–∞–ª–µ–Ω—ã)'}")
    logger.info("")
    logger.info(f"üéØ –î–∞–Ω–Ω—ã–µ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã –≤ VictoriaMetrics: {args.vm_url.replace('/api/v1/import/prometheus', '')}")
    logger.info("")
    logger.info("="*80)
    
    print("\n‚úÖ Pipeline –≤—ã–ø–æ–ª–Ω–µ–Ω —É—Å–ø–µ—à–Ω–æ!")
    print(f"‚è±Ô∏è  –í—Ä–µ–º—è: {total_time:.1f} —Å–µ–∫ ({total_time/60:.1f} –º–∏–Ω)")
    print(f"üìä –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –¥–∞–Ω–Ω—ã–µ: curl {args.vm_url.replace('/api/v1/import/prometheus', '/api/v1/status/tsdb')}")

if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        logger.warning("\n‚ö†Ô∏è  Pipeline –ø—Ä–µ—Ä–≤–∞–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º (Ctrl+C)")
        sys.exit(130)
    except Exception as e:
        logger.error(f"\n‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}", exc_info=True)
        sys.exit(1)

